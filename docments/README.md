# mermaid記法について
https://mermaid.js.org/syntax/sequenceDiagram.html


# 現状の仕様
## APIは同期処理
同期処理で動かしている。データの共有はdockerのsharedボリュームを使っている。
コンテナ内では以下のように見える
```
/shared/bcrlapi/json/
    request.json
    response.json
```
フラグファイルもここに格納する
request.jsonとresponse.jsonを監視してもいいかもしれないが、仕様が分かりにくくなるかも。
watchdogによるフラグの監視も未実装

# TBD
一覧
- そもそもAPIを提供する必要はあるのか
- APIの並列処理

# そもそもAPIを提供する必要はあるのか
ユーザがAPIのレスポンスを使ってリアルタイムで自動化するしたいのであればAPI化する価値はある。  
一方で１日数回実行するだけで、結果は分析に使ったり、手動で何かにインプットしたいだけならwebサーバ上でGUIを作ってログインしてもらい、データのインプット・アウトプットはGUI上操作して計算結果をcsvなりJSONなりで出力してあげればいい気がする。  
研究用サーバの処理時間が15分程度と非常に長いときがあるので、APIとしての/リアルタイム性はそこまで必要ないのではないか？

## APIの並列処理
### 前提
1. APIがたたかれる頻度：30分に1回
2. 応答時間時間：1分~15分
3. 並列処理したいリクエスト数：？
### リクエストの管理方法
- リクエストIDをローカルの辞書で管理  
実装は楽だが、ローカルの容量を食うのでスケールができない。
リクエストは処理が終わるまで待たせて、レスポンスは処理結果を返す。
- backgroundタスク :star: 非同期をやるならこれがよさそう  
リクエストは即時応答してリクエストIDと処理状態のみ返却、処理結果は別のURIで取得させる。
前提2を踏まえるとこれがいい気がする。  
ユーザはレスポンスのデータをどう使うのか次第で、レスポンスの処理を自動化させたい人達にとっては使いにくくなる。  
結果を見たいだけならwebサーバで画面を作ってデータはそこからcsvなりJSONなりで出力してあげればいい気がする。  
- Queueを使う  
実装難易度が高い。管理が大変そう。
- DBを使う  
実装難易度が高い。管理が大変そう。

### 計算部分とAPIの分離
研究用サーバは同期処理しかできないので  
- 研究用サーバのmain.pyにAPIサーバを実装する
ただでさえ重いコンテナにさらに機能を追加するのはつらい
- pythonを実行ファイル化してもらう  
インプット・アウトプットのファイルの管理がだるそう、開発コストが高すぎる。
- APIサーバからSSHで研究用サーバのmain.pyを叩きに行く  
応答速度を犠牲にすれば割とありかもしれない。
- 研究用サーバを複数建てる  
お金の力ですべてを解決できる
